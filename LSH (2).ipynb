{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "KHVTmGdD6R1H"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import urllib.request as request\n",
        "from contextlib import closing\n",
        "\n",
        "# first we download the Sift1M dataset\n",
        "with closing(request.urlopen('ftp://ftp.irisa.fr/local/texmex/corpus/sift.tar.gz')) as r:\n",
        "    with open('sift.tar.gz', 'wb') as f:\n",
        "        shutil.copyfileobj(r, f)\n",
        "import tarfile\n",
        "\n",
        "# the download leaves us with a tar.gz file, we unzip it\n",
        "tar = tarfile.open('sift.tar.gz', \"r:gz\")\n",
        "tar.extractall()\n",
        "def read_fvecs(fp):\n",
        "    a = np.fromfile(fp, dtype='int32')\n",
        "    d = a[0]\n",
        "    return a.reshape(-1, d + 1)[:, 1:].copy().view('float32')\n",
        "\n",
        "# 1M samples\n",
        "xb = read_fvecs('./sift/sift_base.fvecs')\n",
        "# queries\n",
        "xq = read_fvecs('./sift/sift_query.fvecs')"
      ],
      "metadata": {
        "id": "tJjH3OIT57c1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "I79z4bftlfSc"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "LSH Locality Sensitive Hashing\n",
        "- indexing for nearest neighbour searches in sublinear time\n",
        "\n",
        "simple tutorial implementation based on\n",
        "A. Andoni and P. Indyk, \"Near-optimal hashing algorithms for approximate nearest neighbor in high dimensions\"\n",
        "http://people.csail.mit.edu/indyk/p117-andoni.pdf\n",
        "\"\"\"\n",
        "\n",
        "import random\n",
        "from collections import defaultdict\n",
        "from operator import itemgetter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LSHIndex:\n",
        "\n",
        "    def __init__(self,hash_family,k,L):\n",
        "        self.hash_family = hash_family\n",
        "        self.k = k\n",
        "        self.L = 0\n",
        "        self.hash_tables = []\n",
        "        self.resize(L)\n",
        "\n",
        "    def resize(self,L):\n",
        "        \"\"\" update the number of hash tables to be used \"\"\"\n",
        "        if L < self.L:\n",
        "            self.hash_tables = self.hash_tables[:L]\n",
        "        else:\n",
        "            # initialise a new hash table for each hash function\n",
        "            hash_funcs = [[self.hash_family.create_hash_func() for h in range(self.k)] for l in range(self.L,L)]\n",
        "            self.hash_tables.extend([(g,defaultdict(lambda:[])) for g in hash_funcs])\n",
        "\n",
        "    def hash(self,g,p):\n",
        "        return self.hash_family.combine([h.hash(p) for h in g])\n",
        "\n",
        "    def index(self,points):\n",
        "        \"\"\" index the supplied points \"\"\"\n",
        "        self.points = points\n",
        "        for g,table in self.hash_tables:\n",
        "            for ix,p in enumerate(self.points):\n",
        "                table[self.hash(g,p)].append(ix)\n",
        "        # reset stats\n",
        "        self.tot_touched = 0\n",
        "        self.num_queries = 0\n",
        "\n",
        "    def query(self,q,metric,max_results):\n",
        "        \"\"\" find the max_results closest indexed points to q according to the supplied metric \"\"\"\n",
        "        candidates = set()\n",
        "        for g,table in self.hash_tables:\n",
        "            matches = table.get(self.hash(g,q),[])\n",
        "            candidates.update(matches)\n",
        "        # update stats\n",
        "        self.tot_touched += len(candidates)\n",
        "        self.num_queries += 1\n",
        "        # rerank candidates\n",
        "        candidates = [(ix,metric(q,self.points[ix])) for ix in candidates]\n",
        "        candidates.sort(key=itemgetter(1))\n",
        "        return candidates[:max_results]\n",
        "\n",
        "    def get_avg_touched(self):\n",
        "        \"\"\" mean number of candidates inspected per query \"\"\"\n",
        "        return self.tot_touched/self.num_queries"
      ],
      "metadata": {
        "id": "J1VDly6ulsJx"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class L1HashFamily:\n",
        "\n",
        "    def __init__(self,w,d):\n",
        "        self.w = w\n",
        "        self.d = d\n",
        "\n",
        "    def create_hash_func(self):\n",
        "        # each L1Hash is initialised with a different random partition vector\n",
        "        return L1Hash(self.rand_partition(),self.w)\n",
        "\n",
        "    def rand_partition(self):\n",
        "        return [random.uniform(0,self.w) for i in range(self.d)]\n",
        "\n",
        "    def combine(self,hashes):\n",
        "        \"\"\"\n",
        "        combine hash values naively with str()\n",
        "        - in a real implementation we can mix the values so they map to integer keys\n",
        "        into a conventional map table\n",
        "        \"\"\"\n",
        "        return str(hashes)"
      ],
      "metadata": {
        "id": "_4nYjQqelvZX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class L1Hash:\n",
        "\n",
        "    def __init__(self,S,w):\n",
        "        self.S = S\n",
        "        self.w = w\n",
        "\n",
        "    def hash(self,vec):\n",
        "        # use str() as a naive way of forming a single value\n",
        "        return str([int((vec[i]-s)/self.w) for i,s in enumerate(self.S)])\n",
        "\n",
        "def L1_norm(u,v):\n",
        "        return sum(abs(u[i]-v[i]) for i in range(len(u)))\n",
        "\n",
        "def dot(u,v):\n",
        "    return sum(ux*vx for ux,vx in zip(u,v))\n",
        "\n",
        "class L2HashFamily:\n",
        "\n",
        "    def __init__(self,w,d):\n",
        "        self.w = w\n",
        "        self.d = d\n",
        "\n",
        "    def create_hash_func(self):\n",
        "        # each L2Hash is initialised with a different random projection vector and offset\n",
        "        return L2Hash(self.rand_vec(),self.rand_offset(),self.w)\n",
        "\n",
        "    def rand_vec(self):\n",
        "        return [random.gauss(0,1) for i in range(self.d)]\n",
        "\n",
        "    def rand_offset(self):\n",
        "        return random.uniform(0,self.w)\n",
        "\n",
        "    def combine(self,hashes):\n",
        "        \"\"\"\n",
        "        combine hash values naively with str()\n",
        "        - in a real implementation we can mix the values so they map to integer keys\n",
        "        into a conventional map table\n",
        "        \"\"\"\n",
        "        return str(hashes)\n"
      ],
      "metadata": {
        "id": "L2vPbYyllzDK"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class L2Hash:\n",
        "\n",
        "    def __init__(self,r,b,w):\n",
        "        self.r = r\n",
        "        self.b = b\n",
        "        self.w = w\n",
        "\n",
        "    def hash(self,vec):\n",
        "        return int((dot(vec,self.r)+self.b)/self.w)\n",
        "\n",
        "def L2_norm(u,v):\n",
        "        return sum((ux-vx)**2 for ux,vx in zip(u,v))**0.5\n",
        "\n",
        "class CosineHashFamily:\n",
        "\n",
        "    def __init__(self,d):\n",
        "        self.d = d\n",
        "\n",
        "    def create_hash_func(self):\n",
        "        # each CosineHash is initialised with a random projection vector\n",
        "        return CosineHash(self.rand_vec())\n",
        "\n",
        "    def rand_vec(self):\n",
        "        return [random.gauss(0,1) for i in range(self.d)]\n",
        "\n",
        "    def combine(self,hashes):\n",
        "        \"\"\" combine by treating as a bitvector \"\"\"\n",
        "        return sum(2**i if h > 0 else 0 for i,h in enumerate(hashes))"
      ],
      "metadata": {
        "id": "opiIa1Ujl2l6"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CosineHash:\n",
        "\n",
        "    def __init__(self,r):\n",
        "        self.r = r\n",
        "\n",
        "    def hash(self,vec):\n",
        "        return self.sgn(dot(vec,self.r))\n",
        "\n",
        "    def sgn(self,x):\n",
        "        return int(x>0)\n",
        "\n",
        "def cosine_distance(u,v):\n",
        "    return 1 - dot(u,v)/(dot(u,u)*dot(v,v))**0.5\n"
      ],
      "metadata": {
        "id": "7Wxz7Z3dl6n8"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSHTester:\n",
        "    \"\"\"\n",
        "    grid search over LSH parameters, evaluating by finding the specified\n",
        "    number of nearest neighbours for the supplied queries from the supplied points\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,points,queries,num_neighbours):\n",
        "        self.points = points\n",
        "        self.queries = queries\n",
        "        self.num_neighbours = num_neighbours\n",
        "\n",
        "    def run(self,name,metric,hash_family,k_vals,L_vals):\n",
        "        \"\"\"\n",
        "        name: name of test\n",
        "        metric: distance metric for nearest neighbour computation\n",
        "        hash_family: hash family for LSH\n",
        "        k_vals: numbers of hashes to concatenate in each hash function to try in grid search\n",
        "        L_vals: numbers of hash functions/tables to try in grid search\n",
        "        \"\"\"\n",
        "        exact_hits = [[ix for ix,dist in self.linear(q,metric,self.num_neighbours+1)] for q in self.queries]\n",
        "\n",
        "        print(name)\n",
        "        print ('L\\tk\\tacc\\ttouch')\n",
        "        for k in k_vals:        # concatenating more hash functions increases selectivity\n",
        "            lsh = LSHIndex(hash_family,k,0)\n",
        "            for L in L_vals:    # using more hash tables increases recall\n",
        "                lsh.resize(L)\n",
        "                lsh.index(self.points)\n",
        "\n",
        "                correct = 0\n",
        "                for q,hits in zip(self.queries,exact_hits):\n",
        "                    lsh_hits = [ix for ix,dist in lsh.query(q,metric,self.num_neighbours+1)]\n",
        "                    # if lsh_hits == hits:\n",
        "                    #     correct += 1\n",
        "                    if cosine_distance(self.points[lsh_hits[0]],q) < 0.05:\n",
        "                      # print(lsh_hits, hits)\n",
        "                      correct+=1.\n",
        "                    # print(q)\n",
        "                print (\"{0}\\t{1}\\t{2}\\t{3}\".format(L,k,float(correct)/self.queries.shape[0],float(lsh.get_avg_touched())))\n",
        "\n",
        "    def linear(self,q,metric,max_results):\n",
        "        \"\"\" brute force search by linear scan \"\"\"\n",
        "        candidates = [(ix,metric(q,p)) for ix,p in enumerate(self.points)]\n",
        "        return sorted(candidates,key=itemgetter(1))[:max_results]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "24d8lE5Qlkkx"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sigma = 0.1  # adjust as needed\n",
        "\n",
        "# Generate Gaussian noise with the same dimensionality as the query vector\n",
        "\n",
        "\n",
        "# Perturb the query vector by adding the noise\n",
        "perturbed_queries = []\n",
        "for i in range(1000):\n",
        "  noise = np.random.normal(loc=0.0, scale=sigma, size=xb[0].shape)\n",
        "  # print(noise)\n",
        "  perturbed_query = xb[i] + noise\n",
        "  # perturbed_query /= np.linalg.norm(perturbed_query)\n",
        "  perturbed_queries.append(perturbed_query)\n",
        "\n",
        "# Normalize the perturbed query vector to unit length\n",
        "\n",
        "\n",
        "# # Print the original and perturbed query vectors\n",
        "print(\"Original query vector:\", xb[0])\n",
        "print(\"Perturbed query vector:\", perturbed_queries[0])"
      ],
      "metadata": {
        "id": "ZfVCy3M5Ok7P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16f20552-fa73-44ae-a55a-abc6cbb5385f"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original query vector: [  0.  16.  35.   5.  32.  31.  14.  10.  11.  78.  55.  10.  45.  83.\n",
            "  11.   6.  14.  57. 102.  75.  20.   8.   3.   5.  67.  17.  19.  26.\n",
            "   5.   0.   1.  22.  60.  26.   7.   1.  18.  22.  84.  53.  85. 119.\n",
            " 119.   4.  24.  18.   7.   7.   1.  81. 106. 102.  72.  30.   6.   0.\n",
            "   9.   1.   9. 119.  72.   1.   4.  33. 119.  29.   6.   1.   0.   1.\n",
            "  14.  52. 119.  30.   3.   0.   0.  55.  92. 111.   2.   5.   4.   9.\n",
            "  22.  89.  96.  14.   1.   0.   1.  82.  59.  16.  20.   5.  25.  14.\n",
            "  11.   4.   0.   0.   1.  26.  47.  23.   4.   0.   0.   4.  38.  83.\n",
            "  30.  14.   9.   4.   9.  17.  23.  41.   0.   0.   2.   8.  19.  25.\n",
            "  23.   1.]\n",
            "Perturbed query vector: [-6.53866694e-02  1.58747682e+01  3.50888090e+01  4.98770471e+00\n",
            "  3.21728997e+01  3.10615921e+01  1.39129996e+01  1.00420418e+01\n",
            "  1.10574493e+01  7.80564922e+01  5.50075794e+01  1.00426010e+01\n",
            "  4.49066618e+01  8.30930275e+01  1.10358401e+01  6.04252098e+00\n",
            "  1.38683968e+01  5.69944161e+01  1.01960298e+02  7.50420720e+01\n",
            "  1.99531487e+01  8.10254543e+00  2.96046402e+00  4.94927399e+00\n",
            "  6.71604574e+01  1.69683938e+01  1.89064883e+01  2.61159472e+01\n",
            "  4.93628876e+00  9.80662740e-03  1.10050264e+00  2.20681363e+01\n",
            "  5.99096858e+01  2.58267047e+01  6.93799407e+00  9.70467030e-01\n",
            "  1.80252626e+01  2.20687823e+01  8.39529527e+01  5.30881342e+01\n",
            "  8.50266099e+01  1.19009470e+02  1.18991096e+02  3.88946480e+00\n",
            "  2.40027761e+01  1.80736188e+01  7.07540700e+00  7.05531486e+00\n",
            "  9.51783058e-01  8.09156465e+01  1.05925785e+02  1.01957420e+02\n",
            "  7.22216048e+01  2.99452025e+01  5.97960723e+00  8.43296244e-02\n",
            "  8.96976682e+00  9.27660485e-01  9.04385785e+00  1.18982199e+02\n",
            "  7.19686905e+01  8.53937341e-01  3.94419140e+00  3.30880501e+01\n",
            "  1.18946923e+02  2.89578419e+01  6.09738056e+00  1.03145862e+00\n",
            " -8.40256086e-02  9.65084221e-01  1.39225581e+01  5.20175873e+01\n",
            "  1.19022219e+02  3.00517528e+01  3.02914936e+00 -8.62081755e-02\n",
            "  3.32870558e-02  5.50078675e+01  9.20120710e+01  1.11111593e+02\n",
            "  1.98218642e+00  4.92944310e+00  4.05184582e+00  8.86435916e+00\n",
            "  2.19944213e+01  8.90199685e+01  9.61354194e+01  1.40484292e+01\n",
            "  8.68769886e-01  1.20828149e-01  9.95220622e-01  8.20128313e+01\n",
            "  5.90486146e+01  1.60779666e+01  1.98796692e+01  4.91590269e+00\n",
            "  2.49400465e+01  1.39918791e+01  1.10444246e+01  3.79231327e+00\n",
            " -3.36470150e-03  4.71055558e-02  9.59650011e-01  2.58387221e+01\n",
            "  4.69430954e+01  2.30494638e+01  3.89568671e+00 -2.12232212e-01\n",
            "  5.27150327e-02  4.13539406e+00  3.80457999e+01  8.27591848e+01\n",
            "  2.98359265e+01  1.39831317e+01  9.13221636e+00  4.07692135e+00\n",
            "  9.11072495e+00  1.70029878e+01  2.30829491e+01  4.10667167e+01\n",
            "  1.45611692e-01  1.25430748e-01  1.93991258e+00  8.04275361e+00\n",
            "  1.89141360e+01  2.48779226e+01  2.29673357e+01  1.08615891e+00]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perturbed_queries = np.array(perturbed_queries)\n",
        "perturbed_queries.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bMwjQffOmY3",
        "outputId": "bbd83381-9d50-4245-fd5e-98a86537abea"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 128)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # create a test dataset of vectors of non-negative integers\n",
        "    d = 128\n",
        "    # xmax = 20\n",
        "    num_points = 1000\n",
        "    # points = xb\n",
        "    # points = xb.tolist()\n",
        "    points = xb[:num_points].tolist()\n",
        "    # points = [[random.randint(0,20) for i in range(d)] for j in range(num_points)]\n",
        "    # print(points)\n",
        "    # seed the dataset with a fixed number of nearest neighbours\n",
        "    # within a given small \"radius\"\n",
        "    num_neighbours = 10\n",
        "    radius = 0.1\n",
        "    for point in points[:num_points]:\n",
        "      for i in range(num_neighbours):\n",
        "        points.append([x+random.uniform(-radius,radius) for x in point])\n",
        "\n",
        "    # test lsh versus brute force comparison by running a grid\n",
        "    # search for the best lsh parameter values for each family\n",
        "    tester = LSHTester(points, perturbed_queries,num_neighbours)\n",
        "\n",
        "    # args = {'name':'L2',\n",
        "    #         'metric':L2_norm,\n",
        "    #         'hash_family':L2HashFamily(10*radius,d),\n",
        "    #         'k_vals':[8],\n",
        "    #         'L_vals':[16]}\n",
        "    # tester.run(**args)\n",
        "\n",
        "    # args = {'name':'L1',\n",
        "    #         'metric':L1_norm,\n",
        "    #         'hash_family':L1HashFamily(10*radius,d),\n",
        "    #         'k_vals':[4,8],\n",
        "    #         'L_vals':[8,16]}\n",
        "    # tester.run(**args)\n",
        "\n",
        "    args = {'name':'cosine',\n",
        "            'metric':cosine_distance,\n",
        "            'hash_family':CosineHashFamily(d),\n",
        "            'k_vals':[16],\n",
        "            'L_vals':[8]}\n",
        "    tester.run(**args)\n",
        "    # print(points)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEGO16Qq96Pj",
        "outputId": "40f6871d-64c0-4867-8eb9-494c01119934"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cosine\n",
            "L\tk\tacc\ttouch\n",
            "8\t16\t1.0\t523.411\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LSHTester:\n",
        "    \"\"\"\n",
        "    grid search over LSH parameters, evaluating by finding the specified\n",
        "    number of nearest neighbours for the supplied queries from the supplied points\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,points,queries,num_neighbours):\n",
        "        self.points = points\n",
        "        self.queries = queries\n",
        "        self.num_neighbours = num_neighbours\n",
        "\n",
        "    def run(self,name,metric,hash_family,k_vals,L_vals):\n",
        "        \"\"\"\n",
        "        name: name of test\n",
        "        metric: distance metric for nearest neighbour computation\n",
        "        hash_family: hash family for LSH\n",
        "        k_vals: numbers of hashes to concatenate in each hash function to try in grid search\n",
        "        L_vals: numbers of hash functions/tables to try in grid search\n",
        "        \"\"\"\n",
        "        exact_hits = [[ix for ix,dist in self.linear(q,metric,self.num_neighbours+1)] for q in self.queries]\n",
        "\n",
        "        print(name)\n",
        "        print ('L\\tk\\tacc\\ttouch')\n",
        "        for k in k_vals:        # concatenating more hash functions increases selectivity\n",
        "            \n",
        "            lsh = LSHIndex(hash_family,k,0)\n",
        "            for L in L_vals:    # using more hash tables increases recall\n",
        "                lsh.resize(L)\n",
        "                lsh.index(self.points)\n",
        "\n",
        "                correct = 0\n",
        "                for q,hits in zip(self.queries,exact_hits):\n",
        "                    lsh_hits = [ix for ix,dist in lsh.query(q,metric,self.num_neighbours+1)]\n",
        "                    if lsh_hits == hits:\n",
        "                        correct += 1\n",
        "                print (\"{0}\\t{1}\\t{2}\\t{3}\".format(L,k,float(correct)/100,float(lsh.get_avg_touched())))\n",
        "\n",
        "    def linear(self,q,metric,max_results):\n",
        "        \"\"\" brute force search by linear scan \"\"\"\n",
        "        candidates = [(ix,metric(q,p)) for ix,p in enumerate(self.points)]\n",
        "        return sorted(candidates,key=itemgetter(1))[:max_results]"
      ],
      "metadata": {
        "id": "-VtFGNWKvgmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# now define a function to read the fvecs file format of Sift1M dataset\n",
        "def read_fvecs(fp):\n",
        "    a = np.fromfile(fp, dtype='int32')\n",
        "    d = a[0]\n",
        "    return a.reshape(-1, d + 1)[:, 1:].copy().view('float32')"
      ],
      "metadata": {
        "id": "ixtUCHAfv_dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import urllib.request as request\n",
        "from contextlib import closing\n",
        "\n",
        "# first we download the Sift1M dataset\n",
        "with closing(request.urlopen('ftp://ftp.irisa.fr/local/texmex/corpus/sift.tar.gz')) as r:\n",
        "    with open('sift.tar.gz', 'wb') as f:\n",
        "        shutil.copyfileobj(r, f)"
      ],
      "metadata": {
        "id": "kVsFyKJmwAC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "\n",
        "# the download leaves us with a tar.gz file, we unzip it\n",
        "tar = tarfile.open('sift.tar.gz', \"r:gz\")\n",
        "tar.extractall()"
      ],
      "metadata": {
        "id": "d9fElMWJwEoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data we will search through\n",
        "xb = read_fvecs('./sift/sift_base.fvecs')  # 1M samples\n",
        "# also get some query vectors to search with\n",
        "xq = read_fvecs('./sift/sift_query.fvecs')\n",
        "# take just one query (there are many in sift_learn.fvecs)\n",
        "# xq = xq[0].reshape(1, xq.shape[1])"
      ],
      "metadata": {
        "id": "QPrOFg8GwC_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import dot\n",
        "from numpy import linalg as LA\n",
        "def compute_dotproduct(numpoints, numneighbors, dataset, predicted_neighbors):\n",
        "  dots = []\n",
        "  for i in range(0,numpoints):\n",
        "    a = []\n",
        "    for j in range(0,numneighbors):\n",
        "      cosine = (dot(dataset[i],xb[predicted_neighbors[i][j]]))/(LA.norm(dataset[i])*LA.norm(xb[predicted_neighbors[i][j]]))\n",
        "      if cosine > 1:\n",
        "        cosine = 1\n",
        "      a.append(cosine)\n",
        "    dots.append(a)\n",
        "  return dots"
      ],
      "metadata": {
        "id": "_-Nhx1TE1Q3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # create a test dataset of vectors of non-negative integers\n",
        "    # d = 5\n",
        "    # xmax = 20\n",
        "    # num_points = 1000\n",
        "    # points = [[random.randint(0,xmax) for i in range(d)] for j in range(num_points)]\n",
        "    # print(points)\n",
        "    vector_dim = 128          # Dimension (length) of a vector\n",
        "    total_vectors = 1000000   # Number of database vectors\n",
        "    # seed the dataset with a fixed number of nearest neighbours\n",
        "    # within a given small \"radius\"\n",
        "    num_neighbours = 10\n",
        "    # radius = 0.1\n",
        "    # for point in points[:num_points]:\n",
        "    #     for i in range(num_neighbours):\n",
        "    #         points.append([x+random.uniform(-radius,radius) for x in point])\n",
        "\n",
        "    # test lsh versus brute force comparison by running a grid\n",
        "    # search for the best lsh parameter values for each family\n",
        "    tester = LSHTester(xb,xq[0],num_neighbours)\n",
        "    \n",
        "    args = {'name':'cosine',\n",
        "            'metric':cosine_distance,\n",
        "            'hash_family':CosineHashFamily(d),\n",
        "            'k_vals':[16,32,64],\n",
        "            'L_vals':[2,4,8,16]}\n",
        "    tester.run(**args)\n",
        "    # print(points)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "UJ0qYdk1vqUK",
        "outputId": "f85eb720-2cee-4492-f7ea-3b0ac46bba20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-16f9144ebfe0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     args = {'name':'cosine',\n\u001b[1;32m     24\u001b[0m             \u001b[0;34m'metric'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcosine_distance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0;34m'hash_family'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mCosineHashFamily\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;34m'k_vals'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             'L_vals':[2,4,8,16]}\n",
            "\u001b[0;31mNameError\u001b[0m: name 'CosineHashFamily' is not defined"
          ]
        }
      ]
    }
  ]
}