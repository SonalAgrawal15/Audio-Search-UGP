{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uki1R6okmhKM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.cluster.vq import kmeans2, vq\n",
        "from scipy.spatial.distance import cdist\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def PQ_train(vectors, M, k):\n",
        "    s = int(vectors.shape[1] / M)                      # Dimension (or length) of a segment.\n",
        "    codebook = np.empty((M, k, s), np.float32)         \n",
        "        \n",
        "    for m in range(M):\n",
        "        sub_vectors = vectors[:, m*s:(m+1)*s]          # Sub-vectors for segment m.\n",
        "        codebook[m], label = kmeans2(sub_vectors, k)   # Run k-means clustering for each segment.\n",
        "        \n",
        "    return codebook"
      ],
      "metadata": {
        "id": "4L4PCHPzmmeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def PQ_encode(vectors, codebook):\n",
        "    M, k, s = codebook.shape\n",
        "    PQ_code = np.empty((vectors.shape[0], M), np.uint8)\n",
        "    \n",
        "    for m in range(M):\n",
        "        sub_vectors = vectors[:, m*s:(m+1)*s]           # Sub-vectors for segment m.\n",
        "        centroid_ids, _ = vq(sub_vectors, codebook[m])  # vq returns the nearest centroid Ids.\n",
        "        PQ_code[:, m] = centroid_ids                    # Assign centroid Ids to PQ_code.\n",
        "        \n",
        "    return PQ_code"
      ],
      "metadata": {
        "id": "0PO1lbOfmn_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def PQ_search(query_vector, codebook, PQ_code):\n",
        "    M, k, s = codebook.shape\n",
        "    #=====================================================================\n",
        "    # Build the distance table.\n",
        "    #=====================================================================\n",
        "    \n",
        "    distance_table = np.empty((M, k), np.float32)    # Shape is (M, k)    \n",
        "    index= []\n",
        "    for m in range(M):\n",
        "        query_segment = query_vector[m*s:(m+1)*s]    # Query vector for segment m.\n",
        "        distance_table[m] = cdist([query_segment], codebook[m], \"sqeuclidean\")[0]\n",
        "        \n",
        "    #=====================================================================\n",
        "    # Look up the partial distances from the distance table.\n",
        "    #=====================================================================\n",
        "    \n",
        "    N, M = PQ_code.shape\n",
        "    distance_table = distance_table.T               # Transpose the distance table to shape (k, M)\n",
        "    distances = np.zeros((N, )).astype(np.float32)\n",
        "\n",
        "    for n in range(N):                              # For each PQ Code, lookup the partial distances.\n",
        "        for m in range(M):\n",
        "            distances[n] += distance_table[PQ_code[n][m]][m] # Sum the partial distances from all the segments.\n",
        "    index =  np.argsort(distances)      \n",
        "    return index, distances "
      ],
      "metadata": {
        "id": "wvwpwP1cmqCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def PQ(points,queries):\n",
        "  M = 8                     # Number of segments\n",
        "  k = 256                   # Number of centroids per segment\n",
        "  vector_dim = 128          # Dimension (length) of a vector\n",
        "  total_vectors = 1000000   # Number of database vectors\n",
        "  xb = points\n",
        "  t1 = time.perf_counter()\n",
        "  codebook = PQ_train(xb, M, k)\n",
        "  t2 = time.perf_counter()\n",
        "  PQ_code = PQ_encode(xb, codebook)\n",
        "  t3 = time.perf_counter()\n",
        "  time=0\n",
        "  for i in range(queries.shape[0]):\n",
        "    t4 = time.perf_counter()\n",
        "    index, distances = PQ_search(queries[i], codebook, PQ_code)\n",
        "    t5 = time.perf_counter()\n",
        "    print('Top 10 nearest neighbours for queries:', index[0:10])\n",
        "    print('Query search time:', t5-t4, 's')\n",
        "    time+=(t5-t4)\n",
        "\n",
        "  print('Codebook generation time:', t2-t1, 's')\n",
        "  print('Encoding(PQ_code) time for dataset:', t2-t1, 's')\n",
        "  print('Average query search time:', time/(queries.shape[0]))"
      ],
      "metadata": {
        "id": "kHewP2MWmtSU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}